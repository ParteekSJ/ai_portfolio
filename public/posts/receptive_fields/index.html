<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width">



<link rel="icon" type="image/ico" href="http://localhost:1313/favicon_io//favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon_io//favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon_io//favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http://localhost:1313/favicon_io//android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/favicon_io//apple-touch-icon.png">

<meta name="description" content="An LSM Tree overview and Java implementation." />

<title>
    
    Receptive Fields | Parteek Jamwal
    
</title>

<link rel="canonical" href="http://localhost:1313/posts/receptive_fields/" />

<meta property="og:url" content="http://localhost:1313/posts/receptive_fields/">
  <meta property="og:site_name" content="Parteek Jamwal">
  <meta property="og:title" content="Receptive Fields">
  <meta property="og:description" content="An LSM Tree overview and Java implementation.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-12T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-08-12T00:00:00+00:00">
    <meta property="article:tag" content="Database">
    <meta property="article:tag" content="Java">













<link rel="stylesheet" href="/assets/combined.min.480bbb95ddf7e3381ba2b7bf29200e6a7cf114a5011345067aa9e180be2b45a6.css" media="all">



  </head>

  

  
  
  

  <body class="light">

    <div class="content">
      <header>
        

<div class="header">

    

    <h1 class="header-title">
        <a href="http://localhost:1313/">Parteek Jamwal</a>
    </h1>

    <div class="flex">
        

        
        
      
        <p class="small ">
            <a href="/" >
                /home
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/posts" >
                /posts
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/papers" >
                /papers
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/projects" >
                /projects
            </a>
        </p>
        
        
    </div>

    

</div>

      </header>

      <main class="main">
        





<div class="breadcrumbs">
    
    <a href="/">Home</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a href="/posts/">Posts</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a class="breadcrumbs-current" href="/posts/receptive_fields/">Receptive Fields</a>
</div>



<div  class="autonumber" >

  <div class="single-intro-container">

    

    <h1 class="single-title">Receptive Fields</h1>
    
    <p class="single-summary">Receptive Fields Explained</p>
    

    

    <p class="single-readtime">
      
      
      
      <time datetime="2024-08-12T00:00:00&#43;00:00">August 12, 2024</time>
      

      
      &nbsp; · &nbsp;
      7 min read
      
    </p>

  </div>

  

  

  
  <aside class="toc">
    <p><strong>Table of contents</strong></p>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#what-is-receptive-field">What is Receptive Field?</a></li>
    <li><a href="#calculating-the-receptive-field">Calculating the Receptive Field</a></li>
    <li><a href="#code-example">Code Example</a></li>
    <li><a href="#resnets-receptive-fields">ResNet&rsquo;s Receptive Fields</a></li>
  </ul>
</nav>
  </aside>
  

  

  <div class="single-content">
    <h2 id="what-is-receptive-field">What is Receptive Field?</h2>
<p>The “effective receptive field” of a neuron is the area of the original image that influences the activations (output). In other words, it refers to the specific region in the image/feature map that a particular neuron is influenced by. Receptive fields give us a better insight in how CNNs interpret and process spatial hierarchies in data.</p>
<p>To understand this more intuitively, consider the following example</p>
<p>













<figure class=" img-dark%23small">

    <div>
        <img loading="lazy" alt="alt text" src="/assets/posts/receptive_fields/rf_example.png#dark%23small">
    </div>

    
    <div class="caption-container">
        <figcaption> Weight Tying. </figcaption>
    </div>
    
</figure></p>
<p>Each neuron in the CNN depicted in the picture processes a small patch of the input image, defined by the kernel (or filter) size. As presented, the receptive field of the neuron in the <strong>first convolutional layer</strong> is equivalent to the <strong>kernel size of that layer</strong>.</p>
<ul>
<li>Suppose A,B and C are convolutional layers of a CNN (<em>padding $p=1$ to maintain the dimensions, filter size $k=3\times3$ and stride $s=1$</em>).</li>
<li>The &ldquo;receptive field&rdquo; of a &ldquo;neuron&rdquo; in a layer would be the <strong>cross-section of the previous layer from which neurons provide inputs</strong>. With this logic, the RF of $B(2,2)$ is as follows:  $$ \text{RF}[B(2,2)] = A(1:3,1:3) \in \mathbb{R}^{3\times 3} $$ The receptive field of $B(2,2)$ is the $3\times 3$ cross-section in $A$.</li>
<li>Receptive Field of $B(2,4)$ is the $A(3:5,3:5) \in \mathbb{R}^{3\times 3}$.</li>
<li>Lastly, the receptive field of $C(3,3) \in \mathbb{R}^{3\times 3}$ is simply $B(2:4, 2:4)$ which itself receives inputs from $A(1:5,1:5) \in \mathbb{R}^{5\times 5}$.</li>
</ul>
<p>As more convolutional layers are stacked, the receptive field of the neurons in deeper layers grows. This is because each neuron in a deeper layer receives input from multiple neurons in the previous layer, which in turn are influenced by even more extensive areas of the input image. It provides us an insight in the pictorial context captured by the network.</p>
<p>A larger receptive field allows the network to consider more of the surrounding context of a feature, which is crucial for tasks like object detection and segmentation. However, in practice, it is advised to use a stack of small convolutional filters, rather than using a single large convolutional filter. For instance, rather than using a single filter of size $k=5\times5$, stacking 2 convolutional layers (without pooling) with $3\times3$ filters results in a net $5\times5$ filter. Stacking $3$ such layers would give you an effective receptive size of $7\times7$, and so on.</p>
<blockquote>
<p>Better to stack smaller dimensional convolutional layers than to use a single large filter since the computational complexity/cost of stacking small layers is less that using a large filter. Ultimately, the receptive sizes of both paths are the same. The basic idea is to extract local features and then combine them to make more complex patterns. That translates to local transformations and therefore the idea of receptive fields.</p>
</blockquote>
<p>For example, suppose that the input volume has size <code>32x32x3</code>, (e.g. an RGB CIFAR-10 image). If the receptive field (or the filter size) is <code>5x5</code>, then each neuron in the Conv Layer will have weights to a <code>5x5x3</code> region in the input volume, for a total of <code>5*5*3 = 75</code> weights (and +1 bias parameter). Notice that the extent of the connectivity along the depth axis must be 3, since this is the depth of the input volume.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h2 id="calculating-the-receptive-field">Calculating the Receptive Field</h2>
<p>The receptive field (RF) of a &ldquo;neuron&rdquo; in a layer indicates the region of the input that affects that &ldquo;neuron&rdquo;. The formula depends on several factors:</p>
<ol>
<li>Kernel Size ($k$) - Size of the Convolutional Filter.</li>
<li>Stride ($s$) - Step Size of the Convolution.</li>
<li>Padding ($p$) - Amount of padding added to the input (<em>prior convolution</em>)</li>
<li>Receptive Field of the Previous Layer ($\text{RF}_\text{{prev}}$): Size of the RF of previous layer.</li>
</ol>
<p>The formula to compute the receptive field at layer $L$ is as follows: $$ \text{RF}_L = \text{RF}_\text{{prev}} + (k-1) \times \prod_{i=1}^{L-1} s_i $$</p>
<ul>
<li>$\text{RF}_\text{{prev}}$ is the receptive field of the previous layer (or $1$ for the input layer).</li>
<li>$k$ is the kernel size of the current layer.</li>
<li>$s_i$ is the stride of the $i$&lsquo;th layer.</li>
</ul>
<h2 id="code-example">Code Example</h2>
<p>Consider the following <code>SimpleModel</code></p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a90d91">class</span> <span style="color:#3f6e75">SimpleCNN</span>(<span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Module</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#a90d91">def</span> <span style="color:#000">__init__</span>(<span style="color:#5b269a">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#a90d91">super</span>(<span style="color:#000">SimpleCNN</span>, <span style="color:#5b269a">self</span>)<span style="color:#000">.</span><span style="color:#000">__init__</span>()
</span></span><span style="display:flex;"><span>        <span style="color:#5b269a">self</span><span style="color:#000">.</span><span style="color:#000">conv1</span> <span style="color:#000">=</span> <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Conv2d</span>(
</span></span><span style="display:flex;"><span>            <span style="color:#000">in_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">1</span>, <span style="color:#000">out_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">8</span>, <span style="color:#000">kernel_size</span><span style="color:#000">=</span><span style="color:#1c01ce">3</span>, <span style="color:#000">stride</span><span style="color:#000">=</span><span style="color:#1c01ce">1</span>, <span style="color:#000">padding</span><span style="color:#000">=</span><span style="color:#1c01ce">1</span>
</span></span><span style="display:flex;"><span>        )  <span style="color:#177500"># Output shape: [B, 1, 64, 64] -&gt; [B, 8, 64, 64]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#5b269a">self</span><span style="color:#000">.</span><span style="color:#000">conv2</span> <span style="color:#000">=</span> <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Conv2d</span>(
</span></span><span style="display:flex;"><span>            <span style="color:#000">in_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">8</span>, <span style="color:#000">out_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">16</span>, <span style="color:#000">kernel_size</span><span style="color:#000">=</span><span style="color:#1c01ce">3</span>, <span style="color:#000">stride</span><span style="color:#000">=</span><span style="color:#1c01ce">1</span>, <span style="color:#000">padding</span><span style="color:#000">=</span><span style="color:#1c01ce">1</span>
</span></span><span style="display:flex;"><span>        )  <span style="color:#177500"># Output shape: [B, 8, 64, 64] -&gt; [B, 16, 64, 64]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#5b269a">self</span><span style="color:#000">.</span><span style="color:#000">pool</span> <span style="color:#000">=</span> <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">MaxPool2d</span>(
</span></span><span style="display:flex;"><span>            <span style="color:#000">kernel_size</span><span style="color:#000">=</span><span style="color:#1c01ce">2</span>, <span style="color:#000">stride</span><span style="color:#000">=</span><span style="color:#1c01ce">2</span>
</span></span><span style="display:flex;"><span>        )  <span style="color:#177500"># Output shape after pooling: [B, 16, 64, 64] -&gt; [B, 16, 32, 32]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a90d91">def</span> <span style="color:#000">forward</span>(<span style="color:#5b269a">self</span>, <span style="color:#000">x</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#000">x</span> <span style="color:#000">=</span> <span style="color:#5b269a">self</span><span style="color:#000">.</span><span style="color:#000">conv1</span>(<span style="color:#000">x</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#000">x</span> <span style="color:#000">=</span> <span style="color:#000">F</span><span style="color:#000">.</span><span style="color:#000">relu</span>(<span style="color:#000">x</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#000">x</span> <span style="color:#000">=</span> <span style="color:#5b269a">self</span><span style="color:#000">.</span><span style="color:#000">pool</span>(<span style="color:#000">x</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#000">x</span> <span style="color:#000">=</span> <span style="color:#5b269a">self</span><span style="color:#000">.</span><span style="color:#000">conv2</span>(<span style="color:#000">x</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#000">x</span> <span style="color:#000">=</span> <span style="color:#000">F</span><span style="color:#000">.</span><span style="color:#000">relu</span>(<span style="color:#000">x</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#a90d91">return</span> <span style="color:#000">x</span>
</span></span></code></pre></div><p>This simple CNN consists of 2 convolutional layers and 1 pooling layer.</p>
<p>We write a function which is used to calculate the receptive field size of the convolutional and pooling layers. It is as follows:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#177500"># Function to compute the receptive field size manually (approximation)</span>
</span></span><span style="display:flex;"><span><span style="color:#a90d91">def</span> <span style="color:#000">compute_receptive_field</span>(<span style="color:#000">layers</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#000">rf</span> <span style="color:#000">=</span> <span style="color:#1c01ce">1</span>  <span style="color:#177500"># Initial receptive field size</span>
</span></span><span style="display:flex;"><span>    <span style="color:#000">total_stride</span> <span style="color:#000">=</span> <span style="color:#1c01ce">1</span>  <span style="color:#177500"># Initial total stride</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a90d91">for</span> <span style="color:#000">layer</span> <span style="color:#000">in</span> <span style="color:#000">layers</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#a90d91">if</span> <span style="color:#a90d91">isinstance</span>(<span style="color:#000">layer</span>, <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Conv2d</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#000">kernel_size</span> <span style="color:#000">=</span> <span style="color:#000">layer</span><span style="color:#000">.</span><span style="color:#000">kernel_size</span>[<span style="color:#1c01ce">0</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#000">stride</span> <span style="color:#000">=</span> <span style="color:#000">layer</span><span style="color:#000">.</span><span style="color:#000">stride</span>[<span style="color:#1c01ce">0</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#177500"># Update receptive field before updating total stride</span>
</span></span><span style="display:flex;"><span>            <span style="color:#000">rf</span> <span style="color:#000">=</span> <span style="color:#000">rf</span> <span style="color:#000">+</span> (<span style="color:#000">kernel_size</span> <span style="color:#000">-</span> <span style="color:#1c01ce">1</span>) <span style="color:#000">*</span> <span style="color:#000">total_stride</span>
</span></span><span style="display:flex;"><span>            <span style="color:#000">total_stride</span> <span style="color:#000">*=</span> <span style="color:#000">stride</span> <span style="color:#177500"># product of the strides of all previous layers</span>
</span></span><span style="display:flex;"><span>        <span style="color:#a90d91">elif</span> <span style="color:#a90d91">isinstance</span>(<span style="color:#000">layer</span>, <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">MaxPool2d</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#000">kernel_size</span> <span style="color:#000">=</span> <span style="color:#000">layer</span><span style="color:#000">.</span><span style="color:#000">kernel_size</span>
</span></span><span style="display:flex;"><span>            <span style="color:#000">stride</span> <span style="color:#000">=</span> <span style="color:#000">layer</span><span style="color:#000">.</span><span style="color:#000">stride</span>
</span></span><span style="display:flex;"><span>            <span style="color:#177500"># Update receptive field before updating total stride</span>
</span></span><span style="display:flex;"><span>            <span style="color:#000">rf</span> <span style="color:#000">=</span> <span style="color:#000">rf</span> <span style="color:#000">+</span> (<span style="color:#000">kernel_size</span> <span style="color:#000">-</span> <span style="color:#1c01ce">1</span>) <span style="color:#000">*</span> <span style="color:#000">total_stride</span>
</span></span><span style="display:flex;"><span>            <span style="color:#000">total_stride</span> <span style="color:#000">*=</span> <span style="color:#000">stride</span> <span style="color:#177500"># product of the strides of all previous layers</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a90d91">return</span> <span style="color:#000">rf</span>
</span></span></code></pre></div><blockquote>
<p>Receptive field expansion depends on the previous total stride, not the current layer&rsquo;s stride.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#177500"># Define layers</span>
</span></span><span style="display:flex;"><span><span style="color:#000">layers</span> <span style="color:#000">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Conv2d</span>(<span style="color:#000">in_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">3</span>, <span style="color:#000">out_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">64</span>, <span style="color:#000">kernel_size</span><span style="color:#000">=</span><span style="color:#1c01ce">7</span>, <span style="color:#000">stride</span><span style="color:#000">=</span><span style="color:#1c01ce">2</span>),
</span></span><span style="display:flex;"><span>    <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Conv2d</span>(<span style="color:#000">in_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">64</span>, <span style="color:#000">out_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">128</span>, <span style="color:#000">kernel_size</span><span style="color:#000">=</span><span style="color:#1c01ce">3</span>, <span style="color:#000">stride</span><span style="color:#000">=</span><span style="color:#1c01ce">2</span>),
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span><span style="color:#177500"># Compute receptive field</span>
</span></span><span style="display:flex;"><span><span style="color:#000">rf</span> <span style="color:#000">=</span> <span style="color:#000">compute_receptive_field</span>(<span style="color:#000">layers</span>)
</span></span><span style="display:flex;"><span><span style="color:#a90d91">print</span>(<span style="color:#c41a16">f</span><span style="color:#c41a16">&#34;Receptive field size: </span><span style="color:#c41a16">{</span><span style="color:#000">rf</span><span style="color:#c41a16">}</span><span style="color:#c41a16">&#34;</span>)
</span></span></code></pre></div><p>Consider a CNN composed of two convolutional layers.</p>
<ul>
<li>First Convolutional Layer: Kernel Size $7\times 7$, Stride $2$</li>
<li>Second Convolutional Layer: Kernel Size $3\times 3$, Stride $2$</li>
</ul>
<p>We start of by initializing the receptive field(<code>rf</code>), and <code>total_stride</code>. They&rsquo;re both set to a value of $1$.</p>
<ul>
<li>
<p><strong>Layer 1</strong></p>
<ul>
<li>$\text{rf} = \text{rf} + (\text{kernel size} - 1)\times \text{total stride}$</li>
<li>$\text{rf} = 1 + (7 - 1) \times 1 = 7$</li>
<li>Updating $\text{total stride} = \text{total stride} \times \text{stride} = 1\times 2 = 2$</li>
</ul>
</li>
<li>
<p><strong>Layer 2</strong></p>
<ul>
<li>$\text{rf} = \text{rf} + (\text{kernel size} - 1)\times \text{total stride}$</li>
<li>$\text{rf} = 7 + (3 - 1) \times 2 = 9 + 2 \times 1 = 11$</li>
<li>Updating $\text{total stride} = \text{total stride} \times \text{stride} = 2\times 2 = 4$</li>
</ul>
</li>
</ul>
<p>The final receptive field is $11$, i.e., each &ldquo;neuron&rdquo; in the output feature map of the two convolutional layers sees a patch of $5\times 5$ collectively in the previous two layers.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#177500"># Define layers</span>
</span></span><span style="display:flex;"><span><span style="color:#000">layers</span> <span style="color:#000">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Conv2d</span>(<span style="color:#000">in_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">3</span>, <span style="color:#000">out_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">64</span>, <span style="color:#000">kernel_size</span><span style="color:#000">=</span><span style="color:#1c01ce">7</span>, <span style="color:#000">stride</span><span style="color:#000">=</span><span style="color:#1c01ce">2</span>),
</span></span><span style="display:flex;"><span>    <span style="color:#000">nn</span><span style="color:#000">.</span><span style="color:#000">Conv2d</span>(<span style="color:#000">in_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">64</span>, <span style="color:#000">out_channels</span><span style="color:#000">=</span><span style="color:#1c01ce">128</span>, <span style="color:#000">kernel_size</span><span style="color:#000">=</span><span style="color:#1c01ce">3</span>, <span style="color:#000">stride</span><span style="color:#000">=</span><span style="color:#1c01ce">2</span>),
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#177500"># Compute receptive field</span>
</span></span><span style="display:flex;"><span><span style="color:#000">rf</span> <span style="color:#000">=</span> <span style="color:#000">compute_receptive_field</span>(<span style="color:#000">layers</span>)
</span></span><span style="display:flex;"><span><span style="color:#a90d91">print</span>(<span style="color:#c41a16">f</span><span style="color:#c41a16">&#34;Receptive field size: </span><span style="color:#c41a16">{</span><span style="color:#000">rf</span><span style="color:#c41a16">}</span><span style="color:#c41a16">&#34;</span>)
</span></span></code></pre></div><h2 id="resnets-receptive-fields">ResNet&rsquo;s Receptive Fields</h2>
<p>The ResNet architecture is as follows:














<figure class=" img-dark%23small">

    <div>
        <img loading="lazy" alt="alt text" src="/assets/posts/receptive_fields/resnet-model.jpg#dark%23small">
    </div>

    
    <div class="caption-container">
        <figcaption> ResNet Model Architecture </figcaption>
    </div>
    
</figure></p>
<p>The network begins with a single $7\times 7$ convolutional layer with a stride of 2, followed by batch normalization and a ReLU activation function. As mentioned previously, we can also use a stack of smaller kernel size convolutional layersas it is parameter-efficient, however, using a large filter in the initial stages of the network is still very prevalent. Multiple $3\times 3$ filters can achieve a similar receptive field to a single $7\times 7$ convolution. To be precise, two stacked $3\times 3$ convolutional layers have a receptive field of $5\times 5$, and three $3\times 3$ convolutional layers have a receptive field of $7\times 7$. Models like MobileNet or EfficientNet use smaller kernels ($3\times 3$ or $5\times 5$) in the initial set of layers.</p>
<p>Some advantages of using large filters in the initial stages of the network architecture are as follows:</p>
<ol>
<li><strong>Capturing Global Patterns Early</strong>: A $7\times 7$ kernel can capture diverse set of spatial patterns in the input image, such as broader edges or textures, which smaller kernels might miss in the initial stages. Capturing more information in the beginning can provider richer activations/features for subsequent layers to build upon.</li>
<li><strong>Spatial Dimension Reduction</strong>: Often, the first layer uses a stride greater than 1 (e.g., stride 2), which reduces the spatial dimensions of the feature maps. This downsampling decreases computational load for later layers. For instance, if we have an input image of dimensionality $224 \times 224$, and we apply a $7\times 7$ filter with a stride of 2, the output feature dimensionality is $112\times 112$.</li>
</ol>
<p>Larger kernels in the first layer can increase computational cost but may extract more informative features early on. On the contrary, smaller kernels reduce computation but may require deeper networks to capture the same level of detail.</p>
<p>ADD COMPUTATIONS AND IMAGES OF RECEPTIVE FIELDS IN PRACTICE.</p>
<ul>
<li><a href="https://distill.pub/2019/computing-receptive-fields/#solving-receptive-field-region">https://distill.pub/2019/computing-receptive-fields/#solving-receptive-field-region</a></li>
<li><a href="https://youtu.be/ip2HYPC_T9Q?si=sz-YvXhb2ewIT12Q">https://youtu.be/ip2HYPC_T9Q?si=sz-YvXhb2ewIT12Q</a></li>
</ul>

    
  </div>

  


  

  
  

<div class="single-pagination">
    <hr />

    <div class="flex">

        <div class="single-pagination-prev">
            
        </div>

        <div class="single-pagination-next">
            
            <div class="single-pagination-container-next">
                <div class="single-pagination-text">
                    <a href="/posts/cross_entropy_loss/">
                        Cross Entropy Loss
                    </a>
                </div>
                <div class="single-pagination-text">→</div>
            </div>
            
        </div>

    </div>

    <hr />
</div>



  

  

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


      </main>
    </div>

    <footer>
      









<link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">
<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false }
      ]
    });
  });
</script>

    </footer>
    
  </body>

  <script>

  function isAuto() {
    return document.body.classList.contains("auto");
  }

  function setTheme() {
    if (!isAuto()) {
      return
    }

    document.body.classList.remove("auto");
    let cls = "light";
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
      cls = "dark";
    }

    document.body.classList.add(cls);
  }

  function invertBody() {
    document.body.classList.toggle("dark");
    document.body.classList.toggle("light");
  }

  if (isAuto()) {
    window.matchMedia('(prefers-color-scheme: dark)').addListener(invertBody);
  }

  setTheme();

</script>

</html>